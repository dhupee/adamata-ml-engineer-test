{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Adamata Test Notebook","metadata":{"_cell_guid":"68f08dda-be18-466a-8932-2f5c2460541c","_uuid":"717e0f25-995e-434e-a130-4b4bea25670f","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"markdown","source":"## Get python version","metadata":{"_cell_guid":"a84b4b14-c910-4de7-8e31-a174cd354c4f","_uuid":"83d87540-1499-4ecc-8d75-9f302e369fe6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"# This version will decide the version I will use\n!python -V","metadata":{"_cell_guid":"2acf917e-ff2b-4873-8889-10dc114555dd","_uuid":"7676dca3-48b9-49b1-8fed-22ee760e32a5","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Understanding the datasets a little bit\n\nwe're going to download the dataset given from google drive, we just going to use gdown and unzip to download then unzip it.\n\nso...we got 12 images with respective label, and turns out the label is all the same despite the image is different.\n\n```txt\nclass_id center_x center_y width height\n```\n\nif we see from YOLO annotation format, it looks that way, the label is all similar.","metadata":{"_cell_guid":"e8acfa72-3b3d-491a-b8b0-8fb33d4694bd","_uuid":"f5f70035-8b0d-4fc4-9f80-c2f000fec103","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"!pip install gdown","metadata":{"_cell_guid":"8b176653-cb2f-470a-b4e5-bf64e00e4f53","_uuid":"84bb20c9-a642-4501-b613-7f52ba11f417","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"# download and extract given dataset\ndataset_url = \"https://drive.google.com/file/d/1vbMFTe2E5OHp2h5o_YL-RUoIFKxsrZWT/view?usp=sharing\"\ndataset_output_path = \"/kaggle/working/sample.zip\"\n!gdown --fuzzy {dataset_url} -O {dataset_output_path}\n!unzip {dataset_output_path}","metadata":{"_cell_guid":"241fce69-dee7-404f-acdc-9db988313fad","_uuid":"c490b435-24c5-4bd8-8b4e-036d87ab65b3","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_directory = \"/kaggle/working/sample\"\n\nimport os\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndef display_images_from_directory(directory_path):\n    \"\"\"\n    Opens a directory, identifies image files, and displays them in a grid.\n\n    Args:\n        directory_path (str): The path to the directory containing images.\n    \"\"\"\n    image_files = []\n    # Iterate through files in the specified directory\n    for filename in os.listdir(directory_path):\n        # Check if the file is an image (you can extend this list)\n        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n            image_files.append(os.path.join(directory_path, filename))\n\n    if not image_files:\n        print(f\"No image files found in '{directory_path}'\")\n        return\n\n    # Determine grid size for displaying images\n    num_images = len(image_files)\n    cols = int(num_images**0.5)  # Approximate square grid\n    rows = (num_images + cols - 1) // cols # Calculate rows to fit all images\n\n    plt.figure(figsize=(10, 10)) # Adjust figure size as needed\n\n    for i, image_path in enumerate(image_files):\n        try:\n            img = Image.open(image_path)\n            plt.subplot(rows, cols, i + 1)\n            plt.imshow(img)\n            plt.title(os.path.basename(image_path)) # Display filename as title\n            plt.axis('off') # Hide axes for cleaner display\n        except Exception as e:\n            print(f\"Error opening or displaying '{image_path}': {e}\")\n\n    plt.tight_layout() # Adjust subplot parameters for a tight layout\n    plt.show()\n\n# Example usage:\n# Replace 'path/to/your/images' with the actual path to your directory\ndisplay_images_from_directory(dataset_directory)","metadata":{"_cell_guid":"573b69aa-f8ac-41ce-96cd-62ccc938a55b","_uuid":"80d54399-c12d-4095-bb07-17f58fa59497","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cat_txt_files_in_directory(directory_path):\n    \"\"\"\n    Opens a directory and prints the content of all .txt files within it.\n\n    Args:\n        directory_path (str): The path to the directory to process.\n    \"\"\"\n    path_obj = Path(directory_path)\n\n    if not path_obj.is_dir():\n        print(f\"Error: '{directory_path}' is not a valid directory.\")\n        return\n\n    print(f\"Contents of .txt files in '{directory_path}':\\n\")\n    found_txt_files = False\n\n    for item in path_obj.iterdir():\n        if item.is_file() and item.suffix == '.txt':\n            found_txt_files = True\n            print(f\"--- {item.name} ---\")\n            try:\n                with open(item, 'r', encoding='utf-8') as f:\n                    print(f.read())\n                print() # Add a newline for better separation between files\n            except Exception as e:\n                print(f\"Error reading '{item.name}': {e}\")\n    \n    if not found_txt_files:\n        print(\"No .txt files found in this directory.\")\n\ncat_txt_files_in_directory(dataset_directory)","metadata":{"_cell_guid":"8b6a3b49-31c8-4056-838f-fe63909becbb","_uuid":"7a8cda7e-6944-4901-9253-b3750585db15","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Try plot the dataset with the bounding boxes\n\nso the dataset is bunch of image with yolo annotated bounding boxes\n\nlets try to plot it alongside the bounding boxes","metadata":{"_cell_guid":"e4ed5bb2-0bef-4d94-8a9a-31b96b55024b","_uuid":"44ab2735-9764-4d6f-96d9-7289510ec488","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true}},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\ndef display_images_with_bboxes(directory_path):\n    \"\"\"\n    Display images from a directory with YOLO format bounding boxes.\n    \n    Args:\n        directory_path (str): Path to the directory containing jpg and txt files\n    \"\"\"\n    dir_path = Path(directory_path)\n    \n    # Get all jpg files\n    jpg_files = list(dir_path.glob(\"*.jpg\"))\n    \n    if not jpg_files:\n        print(f\"No JPG files found in {directory_path}\")\n        return\n    \n    # Set up the plot\n    fig = plt.figure(figsize=(15, 10))\n    \n    for i, jpg_path in enumerate(jpg_files):\n        # Find corresponding txt file\n        txt_path = jpg_path.with_suffix('.txt')\n        \n        if not txt_path.exists():\n            print(f\"Warning: No corresponding txt file for {jpg_path.name}\")\n            continue\n            \n        # Read image\n        image = cv2.imread(str(jpg_path))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        img_height, img_width = image.shape[:2]\n        \n        # Read bounding boxes from txt file\n        with open(txt_path, 'r') as f:\n            lines = f.readlines()\n        \n        # Draw bounding boxes\n        for line in lines:\n            data = line.strip().split()\n            if len(data) >= 5:  # class_id, x_center, y_center, width, height\n                class_id = int(data[0])\n                x_center = float(data[1]) * img_width\n                y_center = float(data[2]) * img_height\n                width = float(data[3]) * img_width\n                height = float(data[4]) * img_height\n                \n                # Calculate coordinates\n                x1 = int(x_center - width/2)\n                y1 = int(y_center - height/2)\n                x2 = int(x_center + width/2)\n                y2 = int(y_center + height/2)\n                \n                # Draw rectangle\n                cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n                \n                # Add label with class ID\n                label = f'Class {class_id}'\n                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n                \n                # Draw label background\n                cv2.rectangle(image, (x1, y1 - label_size[1] - 5), \n                             (x1 + label_size[0], y1), (255, 0, 0), -1)\n                \n                # Draw label text\n                cv2.putText(image, label, (x1, y1 - 5), \n                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n        \n        # Display image\n        plt.subplot(3, 4, i+1)  # Adjust grid size as needed\n        plt.imshow(image)\n        plt.title(jpg_path.name)\n        plt.axis('off')\n        \n        # Stop if we've displayed 12 images (adjust as needed)\n        if i + 1 >= 12:\n            break\n    \n    plt.tight_layout()\n    plt.show()\n\n# Usage example:\ndisplay_images_with_bboxes(dataset_directory)","metadata":{"_cell_guid":"d041424c-9036-4e46-880d-a2aa852035fd","_uuid":"f927e13f-c8ca-4f40-a31c-ba5818cb28d6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## What we know from the dataset so far\n\n- It hasnt labelled properly\n- The bounding boxes is tight, so no need readjustment\n- there's only 12 image, so might need augmentation\n- it's not square, hate it\n- and there's one image that miss one object\n\nWhat we will do next is using [Roboflow](https://roboflow.com) to adjust the label, adding augmentation and little bit of preprocessing.\n\nimo, it's ideal if we need non technical ","metadata":{}},{"cell_type":"markdown","source":"## Dataset augmentation, and using it.\n\nUsing Roboflow easy proprocess and augmentation, im able to convert 12 datasets image into 28(limited by Free Plan of Roboflow).\n\npreprocess also squish the image size to 300x300 pixels\n\nFor datasets this size its easy to justify using SaaS like it, for the augmentation we pick this:\n\n- Flip: Horizontal, Vertical\n- Crop: 0% Minimum Zoom, 15% Maximum Zoom\n- Rotation: Between -10° and +10°\n- Brightness: Between -15% and +15%\n- Blur: Up to 1.2px\n- Noise: Up to 0.1% of pixels\n\nThis is to represent variation of images with range of realistic error and skewness of the camera.\n\nThe datasets also automatically splitted into 3 sets:\n\n- 24 Training images\n- 3 Validation images\n- 1 Test image\n\nThe best part of using Roboflow is we can download the dataset using Curl, easy.\n\nI honestly can do that by myself with little bit of code but Roboflow able to reformat the datasets into multiple annotation formats.","metadata":{}},{"cell_type":"markdown","source":"![Roboflow Screenshot](https://github.com/dhupee/adamata-ml-engineer-test/blob/master/img/Screenshot%202025-11-24%20at%2017-01-15%20dataset-annotation%20-%20v3%202-labeled-preprocessed-augmented.png)","metadata":{}},{"cell_type":"markdown","source":"## Picking model to be used\n\nFor easy life, YOLO is probably the most straight forward model to be used, from [Models from ultralytics](https://docs.ultralytics.com/models/) docs, I decided to use Yolov11n, for smallest model of the newest Yolov11.","metadata":{}},{"cell_type":"code","source":"# this dataset isnt inside directory so we need to make new directory\nnew_dataset_url = \"https://app.roboflow.com/ds/Fz6f942UcB?key=qt4eGUWAQp\"\nnew_dataset_path = \"/kaggle/working/labelled.zip\"\nnew_dataset_directory = \"labelled\"\n!curl -L {new_dataset_url} > {new_dataset_path}\n!mkdir {new_dataset_directory}\n!unzip {new_dataset_path} -d {new_dataset_directory}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training the YOLO model","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\nfrom PIL import Image\nimport numpy as np\n\ndata_path = \"/kaggle/working/labelled/data.yaml\"\nimage_size = 300\nmodel = YOLO(\"yolo11n.pt\")\nresults = model.train(data=data_path, epochs=100, imgsz=image_size)","metadata":{"_cell_guid":"a92f5fbe-d6a6-404a-96e2-948f85421ee6","_uuid":"2a6da115-2acb-4cd1-b71b-150a911127ca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null}]}